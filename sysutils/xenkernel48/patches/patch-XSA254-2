$NetBSD: patch-XSA254-2,v 1.1 2018/01/18 10:28:13 bouyer Exp $

From: Andrew Cooper <andrew.cooper3@citrix.com>
Date: Wed, 17 Jan 2018 16:15:25 +0000 (+0100)
Subject: x86/mm: Always set _PAGE_ACCESSED on L4e updates
X-Git-Url: http://xenbits.xen.org/gitweb/?p=xen.git;a=commitdiff_plain;h=049e2f45bfa488967494466ec6506c3ecae5fe0e;hp=49a44f089c59c326828b8aed39bee9743f5802fb

x86/mm: Always set _PAGE_ACCESSED on L4e updates

Signed-off-by: Andrew Cooper <andrew.cooper3@citrix.com>
Reviewed-by: Jan Beulich <jbeulich@suse.com>
master commit: bd61fe94bee0556bc2f64999a4a8315b93f90f21
master date: 2018-01-15 13:53:16 +0000
---

diff --git a/xen/arch/x86/mm.c b/xen/arch/x86/mm.c
index be51d16..c22455d 100644
--- xen/arch/x86/mm.c.orig
+++ xen/arch/x86/mm.c
@@ -1297,11 +1297,23 @@ get_page_from_l4e(
                                          _PAGE_USER|_PAGE_RW);      \
     } while ( 0 )
 
+/*
+ * When shadowing an L4 behind the guests back (e.g. for per-pcpu
+ * purposes), we cannot efficiently sync access bit updates from hardware
+ * (on the shadow tables) back into the guest view.
+ *
+ * We therefore unconditionally set _PAGE_ACCESSED even in the guests
+ * view.  This will appear to the guest as a CPU which proactively pulls
+ * all valid L4e's into its TLB, which is compatible with the x86 ABI.
+ *
+ * At the time of writing, all PV guests set the access bit anyway, so
+ * this is no actual change in their behaviour.
+ */
 #define adjust_guest_l4e(pl4e, d)                               \
     do {                                                        \
         if ( likely(l4e_get_flags((pl4e)) & _PAGE_PRESENT) &&   \
              likely(!is_pv_32bit_domain(d)) )                   \
-            l4e_add_flags((pl4e), _PAGE_USER);                  \
+            l4e_add_flags((pl4e), _PAGE_USER | _PAGE_ACCESSED); \
     } while ( 0 )
 
 #define unadjust_guest_l3e(pl3e, d)                                         \
